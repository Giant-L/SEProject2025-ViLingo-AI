import os
import torch
from datasets import load_dataset, Audio
from transformers import (
    WhisperForConditionalGeneration,
    WhisperProcessor,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
)
from peft import get_peft_model, LoraConfig, TaskType
from dataclasses import dataclass
from typing import Any, Dict, List, Union

# Step 1: åŠ è½½ Whisper æ¨¡å‹å’Œå¤„ç†å™¨
model_name = "openai/whisper-small"
processor = WhisperProcessor.from_pretrained(model_name)
model = WhisperForConditionalGeneration.from_pretrained(model_name)

# Step 2: åŠ è½½æ•°æ®é›†
dataset = load_dataset("json", data_files="finetune_dataset/train.jsonl", split="train", cache_dir="./.cache")
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))

# Step 3: æ·»åŠ  LoRA adapter
lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type=TaskType.SEQ_2_SEQ_LM
)
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# Step 4: æ•°æ®é¢„å¤„ç†å‡½æ•°
def prepare_dataset(batch):
    audio = batch["audio"]
    batch["input_features"] = processor(audio["array"], sampling_rate=audio["sampling_rate"]).input_features[0]
    batch["labels"] = processor.tokenizer(batch["text"]).input_ids
    return batch

# Step 5: æ˜ å°„é¢„å¤„ç†
processed_dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names, num_proc=1)

# Step 6: æ•°æ®æ•´ç†å™¨ (è¿™éƒ¨åˆ†ä»£ç æ˜¯æ­£ç¡®çš„ï¼Œä¿æŒä¸å˜)
@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    processor: Any
    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        input_features = [{"input_features": feature["input_features"]} for feature in features]
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().item():
            labels = labels[:, 1:]
        batch["labels"] = labels
        return batch

# Step 7: å®ä¾‹åŒ–æ•°æ®æ•´ç†å™¨
data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)


# âœ…âœ…âœ… Step 8: æœ€ç»ˆè§£å†³æ–¹æ¡ˆ -> åˆ›å»ºè‡ªå®šä¹‰ Trainer âœ…âœ…âœ…
class CustomSeq2SeqTrainer(Seq2SeqTrainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        """
        é‡å†™ compute_loss å‡½æ•°ã€‚
        è¿™æ˜¯ Trainer å°†æ•°æ®ä¼ é€’ç»™æ¨¡å‹å‰çš„æœ€åä¸€æ­¥ã€‚
        æˆ‘ä»¬åœ¨è¿™é‡Œæ‹¦æˆª 'inputs' å­—å…¸å¹¶è¿›è¡Œä¿®æ­£ã€‚
        """
        # ğŸ•µï¸â€â™‚ï¸ æœ€ç»ˆè¯Šæ–­: æ£€æŸ¥è¿›å…¥ compute_loss çš„ inputs
        print("[DIAGNOSTIC] Inside custom compute_loss. Keys in 'inputs':", list(inputs.keys()))

        # å¦‚æœ 'input_ids' æ„å¤–åœ°å‡ºç°åœ¨è¿™é‡Œï¼Œå°±å¼ºåˆ¶åˆ é™¤å®ƒ
        if 'input_ids' in inputs:
            print("!!! WARNING: 'input_ids' found in inputs dict inside compute_loss. Forcibly removing it. !!!")
            del inputs['input_ids']

        # è°ƒç”¨åŸå§‹çš„ compute_loss å‡½æ•°æ¥å®Œæˆå®é™…çš„è®¡ç®—
        return super().compute_loss(model, inputs, return_outputs)

# Step 9: å®šä¹‰è®­ç»ƒå‚æ•°
use_fp16 = torch.cuda.is_available()

training_args = Seq2SeqTrainingArguments(
    output_dir="./finetune_dataset/output",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    learning_rate=1e-4,
    num_train_epochs=5,
    logging_steps=10,
    save_steps=100,
    save_total_limit=2,
    evaluation_strategy="no",
    fp16=use_fp16,
    report_to="none",
    push_to_hub=False,
)

# Step 10: åˆ›å»ºæˆ‘ä»¬è‡ªå®šä¹‰çš„ Trainer å®ä¾‹
trainer = CustomSeq2SeqTrainer( # <-- ä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰ Trainer
    model=model,
    args=training_args,
    train_dataset=processed_dataset,
    data_collator=data_collator,
    tokenizer=processor.feature_extractor,
)

print("\n--- Starting Training with Custom Trainer ---")
trainer.train()

# Step 11: ä¿å­˜æ¨¡å‹
print("\n--- Training Finished Successfully! Saving model... ---")
model.save_pretrained("./finetune_dataset/finetuned-whisper-lora")
processor.save_pretrained("./finetune_dataset/finetuned-whisper-lora")